{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMpf0nPPscmZOKbLI5r8do0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hiagomereles/MVP-Analise-de-Dados-e-Boas-Praticas/blob/main/MVP_Hiago__An%C3%A1lise_de_Dados_e_Boas_Pr%C3%A1ticas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MVP de Análise de Dados e Boas Práticas\n",
        "\n",
        "## Aluno Hiago Mereles Faustino\n",
        "\n",
        "### Indices de Pobreza no Brasil"
      ],
      "metadata": {
        "id": "u0LLhGFj7lU3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Definição do Problema"
      ],
      "metadata": {
        "id": "FjSDu2Cg9AS-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O dataset utilizado neste MVP será o **Indices de Pobreza no Brasil**. O dataset é proveniente do site: https://economiapopular.com.br e o dataset foi baixado pelo Kaggle: https://www.kaggle.com/datasets/fidelissauro/indices-pobreza-brasil. Este dataset é populado com informações sobre o levantamento de pessoas e famílias no Brasil em situações de Pobreza, Extrema Pobreza e Vulnerabilidade no Brasil, usando como fonte de dados o Cadastro Único e Auxílio Brasil.\n",
        "\n",
        "**Informações sobre os atributos:**\n",
        "\n",
        "1. referencia - Ano de Referencia do Dado Coletado\n",
        "2. periodo - Periodo de referencia do Dado Coletado - posso tirar futuramente\n",
        "3. pobreza - Número de Pessoas em Situação de Pobreza\n",
        "4. ext_pobreza - Numero de Pessoas em situação de Extrema Pobreza\n",
        "5. total - Número Total de Pessoas em Situação de Vulnerabilidade\n",
        "6. pop_estimada - Estimativa Populacional do Período\n",
        "7. por_pobreza - Porcentagem Correspondente da População em Situação de Pobreza\n",
        "8. por_ext_pobreza - Porcentagem Correspondente da População em Situação de Extrema Pobreza\n",
        "9. por_vulnerabilidade - Porcentagem Correspondente da População em Situação de Vulnerabilidade\n",
        "10. familias_pobreza - Numero de Famílias em Situalçao de Pobreza\n",
        "11. familias_ext_pobreza - Numero de Famílias em Situalçao de Extrema Pobreza\n",
        "12. familias_vulnerabilidade - Numero de Famílias em situação de vulnerabilidade\n"
      ],
      "metadata": {
        "id": "5iGvNOpx9IiY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import missingno as ms # para tratamento de missings\n",
        "from matplotlib import cm\n",
        "from pandas import set_option\n",
        "from pandas.plotting import scatter_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier"
      ],
      "metadata": {
        "id": "66OEdL2J-KYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# configuração para não exibir os warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "JNwtuZFmNIpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Carga de Dados"
      ],
      "metadata": {
        "id": "t1U8QtD-ONSp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utilizaremos o pacote Pandas (Phyton Data Analysis Library) para carregar um arquivo.csv com cabeçalho disponível online. Mas iremos alterar o cabeçalho para melhorar a visualização dos dados.\n",
        "Com o dataset carregado, iremos explorá-lo um pouco."
      ],
      "metadata": {
        "id": "ChjVPd-ROSiv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Carrega o arquivo csv usando Pandas e a URL desejada\n",
        "\n",
        "# Informa a URL de importação do dataset\n",
        "url = \"https://raw.githubusercontent.com/hiagomereles/MVP-Analise-de-Dados-e-Boas-Praticas/main/indices_pobreza_consolidado.csv\"\n",
        "\n",
        "# Excluindo colunas do dataset que não seram utilizadas na análise dos dados.\n",
        "colunas_para_excluir = [12,13,14,15,16,17,18,19,20]\n",
        "\n",
        "# Carrega o dataset\n",
        "dataset = pd.read_csv(url)\n",
        "\n",
        "# Exclui as colunas que não utilizaremos nesta análise\n",
        "dataset = dataset.drop(dataset.columns[colunas_para_excluir], axis=1)\n",
        "\n",
        "# Novos nomes para as colunas restantes\n",
        "novos_nomes_colunas = ['referencia','periodo','pobreza','ext_pobreza','total','pop_estimada','por_pobreza','por_ext_pobreza',\n",
        "           'por_vulnerabilidade','familias_pobreza', 'familias_ext_pobreza','familias_vulnerabilidade']\n",
        "\n",
        "# Atribui os novos nomes de colunas\n",
        "dataset.columns = novos_nomes_colunas"
      ],
      "metadata": {
        "id": "ndI7wafDOL31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "E1F-OHLLmte7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.head()"
      ],
      "metadata": {
        "id": "18WE6UeavnHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3. Análise de Dados"
      ],
      "metadata": {
        "id": "JhkBs2hTmyny"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.1. Estatísticas Descritivas\n",
        "\n",
        "Vamos Iniciar examinando as dimensões do dataset, suas informações e alguns exemplos de linhas."
      ],
      "metadata": {
        "id": "touoZ9PKm35J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostra as dimensões do dataset\n",
        "print(dataset.shape)"
      ],
      "metadata": {
        "id": "YMq-SuDlnZRY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e954dbe7-c991-4b23-d39c-705551616246"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(122, 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostra as informações do dataset\n",
        "print(dataset.info())"
      ],
      "metadata": {
        "id": "xKlCZT50DlIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Acima vimos os timos de dados que estão em cada coluna do dataset, quantas linhas cada coluna tem e se existe algum null. No caso não temos nenhum nulo e temos uma coluna chamada \"referencia\" em que o Dtype é o Object, futuramente iremos realizar uma alteração para que o Dtype seja X e possamos utilizar essa coluna como uma coluna de data"
      ],
      "metadata": {
        "id": "gwk95xbkyRTA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostra as 10 primeiras linhas do dataset\n",
        "dataset.head(10)"
      ],
      "metadata": {
        "id": "VvioVp4HWC9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostra as 10 ultimas linhas do dataset\n",
        "dataset.tail(10)"
      ],
      "metadata": {
        "id": "qsl-hoKoWpWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "É sempre importante verificar o tipo dos atributos do dataset, pois pode ser necessário realizar conversões. Já fizemos anteriormente com o comando info, mas vamos ver uma outra forma de verificar a natureza de cada atributo e então exibir um resumo estatístico do dataset."
      ],
      "metadata": {
        "id": "rCjkYGciW2jN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar o tipo de dataset de cada atributo\n",
        "dataset.dtypes"
      ],
      "metadata": {
        "id": "yjya8TmYWs_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converte a coluna 'referencia' para o tipo de dado de data\n",
        "dataset['referencia'] = pd.to_datetime(dataset['referencia'])\n",
        "\n",
        "# Extrai o ano e o mês da coluna 'referencia'\n",
        "dataset['ano_mes'] = dataset['referencia'].dt.to_period('M')"
      ],
      "metadata": {
        "id": "uAuv-Q-KMTiM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar se a alteração do tipo de dado da coluna referência foi bem sucedida\n",
        "tipo_de_dado_referencia = dataset['referencia'].dtypes\n",
        "\n",
        "print(f\"Tipo de dado da coluna 'referencia': {tipo_de_dado_referencia}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUI-cO3GMXwf",
        "outputId": "39622a57-25cb-4044-cb68-f1a744e2788f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tipo de dado da coluna 'referencia': datetime64[ns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir a opção de formato para exibir números float sem notação científica\n",
        "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
      ],
      "metadata": {
        "id": "qvfNT4OJkq6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Faz um resumo estatístico do dataset (média, desvio padrão, mínimo, máximo e os quartis)\n",
        "dataset.describe()"
      ],
      "metadata": {
        "id": "ox-7-3cdXTtv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2. Visualizações Unimodais\n",
        "Vamos criar agora um gráfico de para cada atributo do dataset para visualizarmos se encontramos alguma distribuição padronizada."
      ],
      "metadata": {
        "id": "QfNsE16bZJ4M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Histograma\n",
        "dataset.hist(figsize = (15,10))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3stB91EtkpU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "O Gráfico de Densidade, ou Density Plot, é bem parecido com o histograma, mas com uma visualização um pouco diferente. Com ele, pode ser mais fácil identificar a distribuição do atributos do dataset. Assim como fizemos com o histograma, vamos criar um density plot para cada atributo do dataset.\n",
        "\n",
        "Veremos que muitos dos atributos têm uma distribuição distorcida. Uma transformação como a Box-Cox, que pode aproximar a distribuição de uma Normal, pode ser útil neste caso."
      ],
      "metadata": {
        "id": "XNneUHfAk7jP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remover a coluna 'referencia' do DataFrame para esta análise (porque a coluna 'referencia' é uma coluna do tipo data e erros podem ocorrer ao criar o Density Plot)\n",
        "dataset_sem_referencia = dataset.drop('referencia', axis=1)\n",
        "\n",
        "# Gerar o gráfico de densidade(Density Plot) usando as colunas restantes\n",
        "dataset_sem_referencia.plot(kind='density', subplots=True, layout=(4, 3), sharex=False, figsize=(15, 10))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lhuvPrMQk80R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos agora trabalhar com boxplots. No **boxblot**, a linha no centro (vermelha) representa o valor da mediana (segundo quartil ou p50). A linha abaixo é o 1o quartil (p25) e a linha acima o terceiro quartil (p75). O boxplot ajuda a ter uma ideia da dispersão dos dataset e os possíveis outliers.\n",
        "\n",
        "*OBS: Se um ponto do dataset é muito distante da média (acima de 3 desvios padrão da média), pode ser considerado outlier.*\n",
        "\n",
        "Nos gráficos bloxplot, veremos que a dispersão dos atributos do dataset é bem diferente."
      ],
      "metadata": {
        "id": "2IO-Yn4Bt5xD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Boxplot\n",
        "dataset.plot(kind = 'box', subplots = True, layout = (4,3), sharex = False, sharey = False, figsize = (15,10))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_8K9asget-fA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vemos acima que temos uma quantidade considerável de outliers na coluna de 'familias_ext_pobreza' e também alguns outliers na coluna das 'familias_vulnerabilidade'"
      ],
      "metadata": {
        "id": "aW5rtZ032kSM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3. Visualizações Gráficas"
      ],
      "metadata": {
        "id": "3BjL46VQkqAj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Comparação de pobreza e extrema pobreza por ano\n",
        "\n",
        "Abaixo realizaremos algumas análises com as informações sobre pobreza e extrema pobreza do dataset. Nesta primeira análise realizaremos uma comparação da quantidade de pessoas em situação de pobreza e extrema pobreza ao longo dos meses e dos anos desse dataset."
      ],
      "metadata": {
        "id": "c8LmxVFFtX1I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtém uma lista de anos\n",
        "anos = dataset['referencia'].dt.year.unique()\n",
        "\n",
        "# Define o número de colunas e linhas para subplots\n",
        "num_colunas = 4\n",
        "num_linhas = (len(anos) + num_colunas - 1) // num_colunas\n",
        "\n",
        "# Ajusta o tamanho da figura\n",
        "fig, axs = plt.subplots(num_linhas, num_colunas, figsize=(20, 4 * num_linhas), sharey=True)\n",
        "\n",
        "# Ajusta o layout para evitar sobreposição\n",
        "plt.tight_layout(pad=3.0)\n",
        "\n",
        "# Itera sobre os anos e cria um gráfico para cada ano\n",
        "for i, ano in enumerate(anos):\n",
        "    dados_ano = dataset[dataset['referencia'].dt.year == ano]\n",
        "\n",
        "    # Calcula o índice do subplot\n",
        "    linha = i // num_colunas\n",
        "    coluna = i % num_colunas\n",
        "\n",
        "    # Plota o gráfico no subplot\n",
        "    ax = axs[linha, coluna]\n",
        "    sns.barplot(x='ano_mes', y='pobreza', data=dados_ano, ax=ax, label='Pobreza', color='blue', alpha=0.7)\n",
        "    sns.barplot(x='ano_mes', y='ext_pobreza', data=dados_ano, ax=ax, label='Extrema Pobreza', color='red', alpha=0.7)\n",
        "\n",
        "    ax.set_title(f'{ano}')\n",
        "    ax.set_xlabel('Mês e Ano')\n",
        "    ax.set_ylabel('Média')\n",
        "    ax.legend()\n",
        "\n",
        "    # Rotaciona os rótulos do eixo x e ajusta o espaçamento\n",
        "    ax.tick_params(axis='x', rotation=45, labelrotation=45)\n",
        "    plt.setp(ax.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
        "\n",
        "# Remove subplots vazios\n",
        "for i in range(len(anos), num_linhas * num_colunas):\n",
        "    fig.delaxes(axs.flatten()[i])\n",
        "\n",
        "# Ajusta o espaçamento entre os subplots\n",
        "plt.subplots_adjust(hspace=0.5)\n",
        "\n",
        "# Ajusta a largura da célula para evitar barras de rolagem\n",
        "from IPython.core.display import display, HTML\n",
        "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
        "\n",
        "# Exibe o gráfico\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "leBmYzgSavmp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Na análise a seguir iremos analisar os dados de forma anual em um gráfico. Assim conseguiremos ter uma noção melhor de alteração no gráfico ao longo prazo."
      ],
      "metadata": {
        "id": "XTWmjy5X4lw0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Converte a coluna 'referencia' para o tipo de dado de data\n",
        "dataset['referencia'] = pd.to_datetime(dataset['referencia'])\n",
        "\n",
        "# Agrupa os dados por ano e calcula as médias\n",
        "dados_por_ano = dataset.groupby(dataset['referencia'].dt.year).mean().reset_index()\n",
        "\n",
        "# Ajusta o tamanho da figura\n",
        "plt.figure(figsize=(15, 6))\n",
        "\n",
        "# Plota o gráfico\n",
        "sns.barplot(x='referencia', y='pobreza', data=dados_por_ano, color='blue', alpha= 0.7, label='Pobreza')\n",
        "sns.barplot(x='referencia', y='ext_pobreza', data=dados_por_ano, color='red', alpha= 0.7, label='Extrema Pobreza')\n",
        "\n",
        "plt.title('Comparação de Pobreza ao longo dos Anos')\n",
        "plt.xlabel('Ano')\n",
        "plt.ylabel('Média de Pobreza e Extrema Pobreza')\n",
        "\n",
        "# Rotaciona os rótulos do eixo x para melhor legibilidade\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "# Exibe o gráfico\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "APTb_cWmJm8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "No gráfico de barrar acima, conseguimos constatar que nos anos de 2015 até 2019 a ambas as taxas vinham decaindo, demonstrando uma menor quantidade de pessoas em situação de vulnerabilidade, mas de 220 adiante vemos um crescimento muito alto de pessoas em extrema pobreza, um dos maiores influenciadores dessa alteração foi a pandemia do Covid-19, o numero de pessoas em situação de pobreza não alterou muito mas o de pessoas em extrema pobreza teve uma crescente bem considerável.\n",
        "\n",
        "Provavelmente, pessoas em situação de pobreza acabaram indo para situação de extrema pobreza por conta do periodo complicado que o país passou, e, além disso outras pessoas com certeza ficaram em situação de pobreza nesse periodo, por isso só vemos aumento de ambas as colunas no gráfico acima."
      ],
      "metadata": {
        "id": "TFGn64IQ4k9B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Tendência Temporal de Pobreza"
      ],
      "metadata": {
        "id": "auEyI2SrtfE-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cria o gráfico de linhas\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.lineplot(x='referencia', y='pobreza', data=dataset)\n",
        "\n",
        "plt.title('Tendência Temporal de Pobreza')\n",
        "plt.xlabel('Ano de Referência')\n",
        "plt.ylabel('Número de Pessoas em Situação de Pobreza')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "2OOKJab6rbFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Acima conseguimos visualizar que a quantidade de pessoas em situação de pobreza estava em declinio até o periodo de 2020 em que se manteve estável de certa forma até 2022 aonde voltou a ter um aumento."
      ],
      "metadata": {
        "id": "8mup5ju06w8T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cria o gráfico de linhas\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.lineplot(x='referencia', y='ext_pobreza', data=dataset)\n",
        "\n",
        "plt.title('Tendência Temporal de Extrema Pobreza')\n",
        "plt.xlabel('Ano de Referência')\n",
        "plt.ylabel('Número de Pessoas em Situação de Extrema Pobreza')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "cI63rVcDrkTv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vemos aqui que tivemos um salto enorme no número de pessoas em situação de pobreza durante o periodo da pandemia."
      ],
      "metadata": {
        "id": "4p56vl8Y7DDN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cria o histograma\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(dataset['por_vulnerabilidade'], bins=20, kde=True)\n",
        "\n",
        "plt.title('Distribuição da Porcentagem de Vulnerabilidade')\n",
        "plt.xlabel('Porcentagem de Vulnerabilidade')\n",
        "plt.ylabel('Contagem')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xGZ1lIKytmsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3. Visualizações Multimodais\n",
        "\n",
        "Ao visualizar as correlações entre os atributos através da matriz de correlação, perceberemos que parece haver alguma estrutura na ordem dos atributos. O azul ao redor da diagonal sugere que os atributos que estão próximos um do outro são geralmente mais correlacionados entre si. Os vermelhos também sugerem alguma correlação negativa moderada, a medida que os atributos\n",
        "\n",
        "Vamos agora verificar a covariância entre as variáveis numéricas do dataset. A **covariância** representa como duas variáveis numéricas estão relacionadas. Existem várias formas de calcular a correlação entre duas variáveis, como por exemplo, o coeficiente de correlação de Pearson, que pode ser:\n",
        "* Próximo de -1 : há uma correlação negativa entre as variáveis,\n",
        "* Próximo de +1: há uma correlação positiva entre as variáveis.\n",
        "* 0: não há correlação entre as variáveis.\n",
        "\n",
        "<i>OBS: Esta informação é relevante porque alguns algoritmos como regressão linear e regressão logística podem apresentar problemas de performance se houver atributos altamente correlacionados. Vale a pena consultar a documentação do algoritmo para verificar se algum tipo de tratamento de dataset é necessário.</i>\n",
        "\n",
        "\n",
        "O código a seguir exibe a matriz de correlação."
      ],
      "metadata": {
        "id": "xdTnrKtjvZ4o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Matriz de Correlação com Matplotlib Seaborn\n",
        "sns.heatmap(dataset.corr(), annot=True, cmap='RdBu');"
      ],
      "metadata": {
        "id": "P4C8MevUvdcD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por sua vez, o gráfico de dispersão (**scatter plot**) mostra o relacionamento entre duas variáveis. Vamos exibir um para cada par de atributos dos dataset, usando o Seaborn."
      ],
      "metadata": {
        "id": "HEN_rCPvvlFf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scatter Plot com Seaborn - Variação 1\n",
        "\n",
        "sns.pairplot(dataset)"
      ],
      "metadata": {
        "id": "4eVcclpyvqTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scatter Plot com Seaborn - Variação 2\n",
        "\n",
        "sns.pairplot(dataset, hue = \"familias_vulnerabilidade\", height = 2.5);"
      ],
      "metadata": {
        "id": "XLtqEPAyxtWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Pré-Processamento de dados\n",
        "\n",
        "Nesta etapa, poderíamos realizar diversas operações de preparação de dados, como por exemplo, tratamento de valores missings (faltantes), limpeza de dados, transformações como one-hot-encoding, seleção de características (feature selection), entre outras não mostradas neste notebook. Lembre-se de não criar uma versão padronizada/normalizada dos dados neste momento (apesar de serem operações de pré-processamento) para evitar o Data Leakage."
      ],
      "metadata": {
        "id": "x53Umwme0reo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sabemos que o datset Diabetes não tem missings aparentes, mas valores \"0\" que parecem ser missings. Vamos então fazer este tratamento e criar uma nova visão do nosso dataset."
      ],
      "metadata": {
        "id": "U9sMmD1YV6kU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# verificando nulls no dataset\n",
        "dataset.isnull().sum()"
      ],
      "metadata": {
        "id": "UrSDchzeV6Mg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1. Normalização e Padronização\n"
      ],
      "metadata": {
        "id": "HgX2prs4aZx0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui veremos exemplos de normalização e padronização realizadas no dataset de indice de pobreza."
      ],
      "metadata": {
        "id": "GFqQ_BZ0sw9h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Realizando a padronização das colunas 'pobreza' e 'ext_pobreza' como exemplo.\n",
        "scaler_pad = StandardScaler()\n",
        "\n",
        "# Selecionando apenas as colunas numéricas do DataFrame\n",
        "numeric_columns = dataset.select_dtypes(include=['float64', 'int64']).columns\n",
        "dataset_numeric = dataset[numeric_columns]\n",
        "\n",
        "# Copiando o DataFrame e aplicando a padronização\n",
        "dataset_padronized = scaler_pad.fit_transform(dataset_numeric)\n",
        "\n",
        "# Convertendo a matriz NumPy de volta para um DataFrame\n",
        "dataset_padronized = pd.DataFrame(dataset_padronized, columns=numeric_columns)\n",
        "\n",
        "# Excluindo a coluna 'periodo' do DataFrame\n",
        "dataset_padronized = dataset_padronized.drop('periodo', axis=1)"
      ],
      "metadata": {
        "id": "_3QtVs9dqyH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Utilizaremos a função head() para visualizarmos as 5 primeiras linhas do dataset sem a padronização\n",
        "dataset.head()"
      ],
      "metadata": {
        "id": "SfND3vHsa3vF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Agora veremos as 5 primeiras linhas do dataset alterado para vermos a diferença que a padronização trouxe as colunas do dataset, excluindo as colunas 'referencia' e 'periodo'.\n",
        "dataset_padronized.head()"
      ],
      "metadata": {
        "id": "qS5_ziuXpcO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Antes da normalização/padronização\n",
        "dataset[['pobreza', 'ext_pobreza']].hist(figsize=(5, 2), bins=20, alpha=0.5)\n",
        "# Adicione um título adicional usando suptitle\n",
        "plt.suptitle('Distribuição Original', y=1.1)\n",
        "#plt.title('Distribuição Original')\n",
        "plt.show()\n",
        "\n",
        "# Depois da normalização\n",
        "dataset_normalized = dataset.copy()\n",
        "scaler_norm = MinMaxScaler()\n",
        "dataset_normalized[['pobreza', 'ext_pobreza']] = scaler_norm.fit_transform(dataset_normalized[['pobreza', 'ext_pobreza']])\n",
        "dataset_normalized[['pobreza', 'ext_pobreza']].hist(figsize=(5, 2), bins=20, alpha=0.5)\n",
        "plt.suptitle('Distribuição Normalizada', y=1.1)\n",
        "plt.show()\n",
        "\n",
        "# Depois da padronização\n",
        "dataset_padronized = dataset.copy()\n",
        "scaler_pad = StandardScaler()\n",
        "dataset_padronized[['pobreza', 'ext_pobreza']] = scaler_pad.fit_transform(dataset_padronized[['pobreza', 'ext_pobreza']])\n",
        "dataset_padronized[['pobreza', 'ext_pobreza']].hist(figsize=(5, 2), bins=20, alpha=0.5)\n",
        "plt.suptitle('Distribuição Padronizada', y=1.1)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "PTE9X7cScgF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Acima temos os gráficos das colunas 'pobreza' e 'ext_pobreza' em sua forma original, normalizada e também padronizada, facilitando assim o entendimento da alteração na escala causada por essas alterações. No caso do dataset utilizado neste projeto, a Normalização é a melhor maneira de facilitar a leitura dos dados."
      ],
      "metadata": {
        "id": "379UwrMwW2du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Antes da normalização/padronização\n",
        "sns.boxplot(data=dataset[['pobreza', 'ext_pobreza']])\n",
        "plt.title('Boxplot Original')\n",
        "plt.show()\n",
        "\n",
        "# Depois da normalização/padronização\n",
        "sns.boxplot(data=dataset_normalized[['pobreza', 'ext_pobreza']])\n",
        "plt.title('Boxplot Normalizado')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "YA2UfEK1dN-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vemos acima que com a utilização da normalização nós conseguimos melhorar a visualização e entendimento dos dados do dataset por conta da proporção dos dados se manter igual, o que muda é a escala em que os dados são demonstrados."
      ],
      "metadata": {
        "id": "c5opxokFvpbH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Estatistica Descritiva"
      ],
      "metadata": {
        "id": "KTSktEXFiukT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Antes da normalização/padronização\n",
        "print(\"Estatísticas Descritivas Original:\")\n",
        "print(dataset[['pobreza', 'ext_pobreza']].describe())\n",
        "\n",
        "# Depois da normalização/padronização\n",
        "print(\"\\nEstatísticas Descritivas Normalizado/Padronizado:\")\n",
        "print(dataset_normalized[['pobreza', 'ext_pobreza']].describe())\n"
      ],
      "metadata": {
        "id": "4qdlz6Uait5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir a opção de formato para exibir números float sem notação científica\n",
        "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
        "\n",
        "# Exibir estatísticas descritivas novamente\n",
        "print(\"Estatísticas Descritivas Original:\")\n",
        "print(dataset.describe())\n",
        "\n",
        "# Restaurar a opção padrão se necessário\n",
        "# pd.reset_option('display.float_format')\n"
      ],
      "metadata": {
        "id": "m19LKfDokPEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2. Separação em conjunto de treino e conjunto de teste\n",
        "\n",
        "É uma boa prática usar um conjunto de teste (na literatura também chamado de conjunto de validação), uma amostra dos dados que não será usada para a construção do modelo, mas somente no fim do projeto para confirmar a precisão do modelo final. É um teste que podemos usar para verificar o quão boa foi a construção do modelo, e para nos dar uma ideia de como o modelo irá performar nas estimativas em dados não vistos. Usaremos 80% do conjunto de dados para modelagem e guardaremos 20% para teste, usando a estratégia train-test-split."
      ],
      "metadata": {
        "id": "IsSEqT3yvs2e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "fazer a separação do dataset em treino e teste"
      ],
      "metadata": {
        "id": "BB5wq_q8wPTV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Definir as features (X) e o target (y)\n",
        "X = dataset.drop(['referencia', 'periodo', 'pobreza', 'ext_pobreza'], axis=1)\n",
        "y = dataset['pobreza']\n",
        "\n",
        "# Separar em conjunto de treino e teste ( 80% treino e 20% teste)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Exibir o número de amostras em cada conjunto\n",
        "print(f'Número de amostras no conjunto de treino: {len(X_train)}')\n",
        "print(f'Número de amostras no conjunto de teste: {len(X_test)}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIMdzetRc0eb",
        "outputId": "08e5582e-d6bc-48cb-ca52-62aeb46117b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de amostras no conjunto de treino: 97\n",
            "Número de amostras no conjunto de teste: 25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusão\n",
        "\n",
        "Neste MVP foi possível verificar que tivemos uma relação entre o aumento da pobreza e da extrema pobreza por conta da pandemia. Vimos claramente a alteração nos gráficos e valores no periodo entre 2020 até o final de 2022.\n",
        "\n",
        "Neste projeto eu poderia ter realizado um maior número de análises, como a média de pessoa por familia em situação de pobreza e extrema pobreza entre outras análises, mas achei interessante focar em demonstrar técnicas diferentes de análise."
      ],
      "metadata": {
        "id": "991p6AHwwqiH"
      }
    }
  ]
}